
#let config = (
  session: "2024至2025学年第一学期",
  teaching_class_number: 20,
  title: "大标题后面再来想",
  cover_name: "莫然",
  college: "计算机学院",
  major: "计算机科学与技术",
  class: "卓越(01)班",
  id: "20230674",
  self_evalue: "一级",
  all_authors: (
    莫然: "20230674",
    赖彦翰: "20230320",
    段雯菀: "20231326"
  ),

  //其他
  reference_title: "参考文献",
)


#import "style/heading.typ": set-heading, custom-numbering
#import "style/font.typ": use-size, font-family
#import "style/cover.typ": inser-background, fill-cover-content
#import "style/abstract.typ": make-abstract
#import "style/task.typ": make-task-page
#import "style/ref.typ": apply-ref-style
#import "style/appendix.typ": apply-appendix-style
#import "@preview/zebraw:0.5.5": *


// 文档内置属性设置，和内容无关
#set document(
  title: [毛概实践报告],
  author: "morethan",
  date: datetime(year: 2025, month: 8, day: 2),
  description: [毛概实践报告的模板],
  keywords: ("毛概", "实践报告", "Typst")
)

//产生封面内容
#fill-cover-content(config)

// 字体配置
#set text(font: font-family.at("SongTi"), use-size("五号"), lang: "zh")

//目录设置
#pagebreak()
#show outline.entry: set block(above: 1.2em)
#let outline_title = text(bottom-edge: "descender", size: use-size("小二"))[目录]
#outline(depth: 4, title: outline_title)

////////////////////// 分工表开始 //////////////////////
#pagebreak()

#make-task-page()[

= 任务概述

此次实践任务大体上分为三个部分：拼好饭口碑分化调查、拼好饭商业模式分析和拼好饭背后的社会经济，从逻辑上形成由浅入深的调查节奏。调查首先从网络热点现象入手，然后理论分析拼好饭背后的商业模式，最后从“拼好饭”这一表层现象去理解当下的社会经济生活。

= 人员分工

== 莫然20230674

+ 起草大致的报告思路
+ 编排报告的模板方便其他成员协同编写报告
+ 完成拼好饭口碑分化调查部分，包括搜集各大社交媒体平台的用户画像数据、“拼好饭”平台的三方用户数据、舆论核心议题词频统计分析、网络调查问卷的设计与数据收集
+ 实地采访中，主要参与对外卖员的实地采访调查

== 赖彦翰20230320

+ 完成外卖市场的商业背景的查找与分析
+ 查找关于外卖平台的商业模式与“拼好饭”平台的商业模式资料。并撰写“传统外卖模式分析”与“拼好饭外卖模式分析”部分。
+ 参与调查问卷数据收集
+ 实地采访中，主要参与对商家的实地采访调查

== 段雯菀20231326

+ 完成摘要部分
+ 完成“拼好饭背后的社会经济”部分的数据收集与分析，并完成撰写
+ 参与调查问卷数据收集
+ 实地采访中，主要参与对消费者的实地采访调查

]

////////////////////// 分工表结束 //////////////////////


//标题样式配置
#set heading(numbering: custom-numbering)
#show heading: it => set-heading(it)

// 页面配置
#set page(paper: "a4", numbering: "1")
#set par(
  first-line-indent: (amount: 2em, all: true),
  justify: true
)

// 列表缩进配置
#set enum(indent: 2em)
#set list(indent: 2em)

// 图片标注配置
#set figure(numbering: "一", supplement: [图片])
#set figure.caption(separator: [：])

// 附录代码块
#show: zebraw

////////////////////// 摘要 //////////////////////

#let abstract = [               
本研究以“拼好饭”这一外卖团餐新模式为观察窗口，围绕“网络舆论—现实消费—社会经济”三条主线，系统考察其在当下的兴起与扩散机制。研究动机在于纠正仅凭舆论声量推断社会事实的偏差，进而通过多源证据揭示：当宏观环境趋于谨慎、居民预算承压时，价格、效率、组织方式如何共同驱动消费结构与产业形态的重组。为此，我们提出三类核心问题：网络空间对“拼好饭”的两极化评价与现实使用行为为何存在显著落差；“拼单+集中配送”的机制如何在成本、运力与供需匹配上重塑外卖价值链；这一现象从消费心理与宏观语境层面折射出哪些当前宏观经济背景的经济特征。

方法上，研究采用分层的比较分析框架：第一层，舆情侧以主流平台为样本，结合平台用户画像与高频话题提取，对“标签化/调侃化”与“品质/价格”取向进行对照；第二层，行为侧以结构化问卷与小样本实地访谈为主，聚焦大学生与初入职场群体，对使用动机、使用场景、风险感知与产业认知进行量化与归纳；第三层，产业/宏观侧基于公开统计与行业资料，对餐饮与外卖的规模、渗透率与价格信号进行纵向—横向比对，以检验前两层发现的外推性与稳健性。全程以“舆论—行为—数据”的三角互证为原则，避免单一数据源带来的偏误。

主要发现有四：其一，网络讨论深受平台文化和受众结构影响，微博、知乎用户更强调品质，容易将“拼好饭”视作“低质”“凑合”，而小红书、B站的潮流与梗文化则放大其低价特征，这类表达带有强烈情绪与身份色彩。其二，现实消费体现预算约束下的理性取舍：价格与补贴是首要动因，性价比评价占优，但在食品安全和长期使用上分歧明显，既有“够用即好”的日常策略，也有“手头紧时的替代”选择。其三，在机制层面，“拼单+集中配送”降低成本、提升效率，形成“用户省支出—商家以价换量—平台以效率补贴价格”的联动，但骑手收入改善有限，显示效率红利分配不均。其四，在宏观层面，“拼好饭”折射出当前消费与产业的三大趋势：居民谨慎支出与价格敏感上升，行业逻辑由补贴驱动转向效率驱动，平台通过低价入口和生态导流实现供需再平衡。

理论与实践贡献在于：第一，方法上以比较分析纠偏“以声量代替事实”的误判，提供舆论与行为解耦的分析范式；第二，机制识别上揭示低价并非补贴战，而是组织方式与履约效率改变的结果，为理解平台经济的成本—效率—生态联动提供证据；第三，政策层面提出“低价普惠—食品安全—劳动条件”三者平衡的议题，提示需以标准化与透明化回应社会关切。研究局限在于样本集中于高校与城市青年、时间窗较短，未来可扩大覆盖范围，结合更长期数据与因果识别设计，比较不同城市与品类下的异质性效果。

综上，“拼好饭”不仅是外卖行业的价格策略，更是居民消费心理变化、平台效率进化与产业组织重构共同作用的结果。它为理解当下中国的消费转向与平台生态演化提供了一个清晰、可量化、可跟踪的观察点：当预算成为首要约束时，谁能以更低的履约成本提供“足够好”的服务，谁就更可能在竞争中获得持续优势。

]

#let key_word = [
  拼好饭；外卖行业；大学生消费；商业模式；社会经济影响
]

#make-abstract(config, abstract, key_word)

////////////////////// 正文 //////////////////////
#counter(heading).update(0) // 从头开始编号
= 引言

近年来，“拼好饭”这一新兴外卖团餐模式迅速走入公众视野，成为诸多打工人和学生群体日常就餐的新选择。不同于传统外卖平台主打的高品质与多样化，“拼好饭”最大的卖点就是极致的性价比：1.9元的蜜雪冰城、3.9元的沪上阿姨、6.9元的塔斯汀三件套套餐等等@sohu20250515。作为外卖界的拼多多，“拼好饭”在网络上也逐渐成为一个热门的名词，评价也呈现两极分化：正面评价认为“拼好饭”为广大普通百姓提供了廉价的饭菜，是惠民利民的良好商业模式，能够刺激消费带动经济增长；而负面评价认为“拼好饭”极低的价格降低了商家利润的同时也难以保证食品的质量。

为了对“拼好饭”这一新兴的外卖模式有更加客观实际的认知，我们小组将目标选定为“拼好饭”进行社会实践调查。

////////////////// 研究背景与问题提出 //////////////////

= 研究背景与问题提出

== 研究背景

中国外卖在近十年中经历了爆发式增长，从一个新兴业态发展迅速成为数千亿规模的成熟产业。无论是在价格亲民性，服务便利性还是配送效率性均达到了全球领先水准。官方数据显示，中国外卖市场规模从2016年的1660亿元人民币快速增长至近年来的新高度——2023年美团全年营收达2767亿元，同比增长26%，即时配送订单达219亿笔@meituan20240322。

2019年末的新冠疫情的袭来，加速了消费者线上餐饮消费习惯的养成，更催生了全新的团购消费模式。特别是在2022年3月至5月上海奥密克戎疫情期间，一项涉及1168名居民的调查显示，高达92.81%的受访者通过在线社区团购购买食品，充分说明了集体采购模式在特殊时期的重要作用@liu2023online。这种集体采购的模式并未随着疫情的结束而消失，反而在后疫情时代得到了进一步发展。

然而，2024年后，外卖行业的高速增长趋势开始放缓，消费市场增长略显乏力，餐饮行业发展面临新的挑战。经过数年的激烈竞争和快速扩张，外卖市场逐渐从增量竞争转向存量博弈。数据显示，2024年1-8月全国餐饮收入为3.5万亿元，同比增长6.6%，创下近十年最低增速（2020年、2022年除外）。其中，8月全国餐饮收入4351亿元，同比增长仅3.3%；限额以上单位餐饮收入1241亿元，同比上升0.4%，增长动能明显不足@china_catering_20250123。

在行业整体增速放缓的背景下，低价竞争成为餐饮行业的显著趋势。众多知名品牌纷纷调整策略，推出低价套餐以争夺市场份额：瑞幸、库迪推出9.9元特价咖啡；肯德基、麦当劳、汉堡王等国际连锁品牌也卷入低价位套餐竞争，其中汉堡王的9.9元吃堡活动上线仅3个月就售出超18万份，充分说明了消费者对低价产品的强烈需求。

更为重要的是，消费者的消费观念正在发生深刻转变。《2024中国青年消费趋势报告》指出，当下年轻消费者愈发审慎精明，注重商品性价比和实际价值。面对价格更低的同类商品时，仅有6.4%的受访者会优先考虑质量、品牌等因素而放弃购买"平替商品"，这一数据清晰地反映了价格因素在消费决策中的主导地位@bjnews_youth_consumption_20240705。

== 研究问题

=== 拼好饭口碑分化调查

为了更加全面深入地分析和理解拼好饭，首先需要从表层现象入手，重点探究一下：1）拼好饭在网络上掀起了热烈的讨论，网友讨论的主要内容和争议点是什么？2）通过问卷调查和实地采访来评估网友讨论的主要观点是否合理？如果不合理那么可能的原因是什么？

通过这部分调查，我们能够更加全面完善地了解到拼好饭热议背后反应的真实现象，而不是片面地关注网络上激烈的言论，忽略“沉默的大多数”，让后续理论分析和结论探究有更加坚实的实践基础。

=== 拼好饭商业模式分析

这部分深入探讨了“拼好饭”这一创新商业模式的内在逻辑，并将其与传统O2O外卖模式进行了对比。我们剖析了传统模式在高成本运营和价格竞争中面临的结构性困境，阐明了其盈利模式的局限性；同时，我们详细分析了“拼好饭”如何通过订单聚合实现规模效应，构建起低成本、高效率的全新价值链，成功切入了对价格敏感的市场，并作为流量入口为平台带来长期的可持续增长。

=== 拼好饭背后的社会经济

最后，我们以拼好饭这一消费现象为切入点，探讨网络舆论与现实消费行为之间的差异，以及由此反映出的居民消费水平与消费意愿的变化。具体而言，我们关注拼好饭在网络舆论中所呈现的两极化态度与现实中较高的接受度之间的反差，思考其背后的社会心理与经济原因；同时考察消费者在经济压力下向理性化与集体化消费转变所体现出的消费结构调整；并结合当下的经济背景，分析拼好饭所折射出的谨慎消费、共享趋势与平台经济优化等经济特征，从而为理解居民消费心态和新型产业模式提供新的研究视角。


////////////////// 研究方法和调查设计 //////////////////

= 研究方法和调查设计

== 拼好饭口碑分化调查

这部分的调查主要涉及三个部分：网络舆情、问卷调查、实地走访

=== 网络舆情

选取微博、小红书、知乎、抖音、哔哩哔哩等主流社交平台作为信息源，同时考虑到各平台对于用户隐私的保护政策，用户的真实年龄、职业等关键用户画像指标难以在公共网络获取，因此需要从平台官方的数据统计中得到用户画像信息。另外还需要关注美团“拼好饭”的用户群体，包括使用者群体、配送者群体和商家群体。在难以获取参与“拼好饭”讨论的用户的隐私数据的情况下，我们认为使用平台的整体用户数据来替代是合理的假设与折中。

为了获取准确的网络舆论的热点话题，我们使用网络爬虫技术，爬取与“拼好饭”相关的高热度帖子与评论，筛选时间范围集中于2024年下半年至2025年上半年。

最后通过高频关键词提取，归纳出网络舆论关注的核心议题，如“价格低廉”“食品安全”“商家盈利困境”“消费降级”等，同时梳理出主要的争议点和立场分歧，为后续问卷设计和观点验证提供方向。

=== 问卷调查

基于舆情分析结果，我们设计了一份结构化问卷，面向在校大学生群体进行投放。问卷主要包含以下几类问题：

- 基础信息采集：性别、年龄段、月消费水平等；

- 使用行为与偏好：是否使用过“拼好饭”，使用频率，选择理由，最关注的因素（价格、配送速度、口味、品牌等）；

- 认知与评价：对“拼好饭”正面和负面评论的认同度，是否担忧食品安全问题，是否愿意长期使用；

我们使用问卷星平台来进行问卷的发放、回收和数据分析整理。

=== 实地走访

为验证问卷数据的真实性与完整性，避免仅依赖“网络上声音最大的人”，我们开展了实地访谈调查，面向部分学生用户、外卖骑手与合作商家。访谈重点关注以下方面：

- 用户端：实际使用体验是否与网上描述一致，是否存在“沉默的大多数”未被表达的观点；

- 商家端：如何看待平台补贴与低价策略，是否对盈利空间和食品标准造成压力；

- 骑手端：“拼好饭”订单对配送效率、劳动强度、收入是否产生影响。

通过这些实地反馈，可以有效校正舆情数据中可能存在的偏见放大效应，从而得出更加贴近现实的研究结论。

为了更好地获取高质量的受访者，我们将用户端的受访者锁定为校园中到“外卖领取点”拿外卖的同学，这些同学一般而言就是外卖的重度消费群体，有更高概率是“拼好饭”平台的实际用户；商家端的受访者是我们小组成员的一位亲戚，其开有一家餐馆，并且入驻了美团“拼好饭”平台，能够提供一手的商家端的信息；外卖骑手端则在“外卖领取点”附近随机寻找一位外卖小哥即可，同时考虑到外卖小哥送餐任务时间紧迫我们选择在送餐低峰期去采访，以获得更加详细准确的采访结果。

== 拼好饭背后的社会经济
=== 比较分析
在研究方法上，我们以比较分析为主要路径，沿用拼好饭口碑分化调查获取的数据，对比网络舆论与现实消费行为之间的差异。网络上对拼好饭的讨论往往带有强烈的情绪化色彩，呈现出“低质”“凑合”的负面标签，而现实调查则显示其在大学生、上班族等群体中具有较高的接受度和持续使用率。通过这种差异化的对比，我们能够从口碑分化的现象中进一步提炼出背后的社会心理与经济逻辑，揭示网络舆论与社会实际之间的张力，并为后续的宏观经济解读奠定基础。

=== 统计数据整理

在宏观层面，我们依托国家统计局、行业研究机构以及主要外卖平台的公开资料，同时参考相关学术研究和媒体报告，对外卖行业及拼好饭模式相关数据进行了系统汇总与再整理。整理工作的重点包括以下几个方面：

1. 外卖行业整体规模、增速与市场渗透率，用于刻画餐饮行业在“后疫情时代”的发展态势，并观察外卖在餐饮总额中所占比重的变化；  
2. 拼好饭模式的渗透情况，包括订单规模、用户规模、入驻品牌数量和城市覆盖率，用以衡量其市场扩张速度与影响力；  
3. 价格与消费结构，重点对比拼好饭的客单价、补贴力度与常规外卖均价的差异，分析其对青年群体特别是大学生消费行为的吸引力；  
4. 劳动市场相关数据，关注骑手的订单完成量、配送效率与收入变化，从而评估拼好饭模式对劳动分工与就业的影响。  

在方法上，我们采用纵向趋势分析与横向指标对比相结合的方式：纵向上，通过连续年份的数据考察外卖市场规模、餐饮收入、用户规模的变化趋势；横向上，则对比不同群体（如学生与非学生）、不同平台和不同城市商家的数据，以揭示拼好饭模式在消费与经营层面的差异性。  

通过这一整理过程，我们为后续的“统计数据结果与分析”奠定了基础，也为问卷调查和实地走访提供了宏观层面的背景支撑，使研究结论更具系统性与解释力。


////////////////// 调查结果与数据分析 //////////////////

= 调查结果与数据分析

== 拼好饭口碑分化调查

=== 网络舆情调查结果

*主流社交平台人群画像。*经过数据分析以及官方数据统计，得出如下调查结果：

+ 哔哩哔哩的主要用户非常年轻，截至2025年一季度末，18至24岁的用户占比高达48%；用户的地域分布总体看来比较均衡，一线、新一线、三四线城市占比均为30%至40%之间；用户在哔哩哔哩上的月均消费意愿不超过1500元@bilibili250701；

+ 新浪微博的用户群体中，90后与00后合计接近 80%，是微博的绝对主力用户群体；一、二、三线城市用户占比超过70%，四线及以下、港澳台、海外占比相对较少；根据手机价位推断消费能力，5000元以上群体占比33.7%，表明微博用户具有较强的消费能力@sina20241217；

+ 抖音的主要用户以年轻群体为主，19至30岁用户占比最高，是核心使用人群；在地域分布上，用户广泛覆盖全国，其中低线城市用户占比更高，但一线、新一线城市同样活跃；在消费意愿方面，年轻用户偏好数码、时尚和娱乐消费，而中年群体更倾向于家庭、汽车和日用品消费@ocean_insights2020；

+ 知乎的主要用户以25至40岁群体为主，占比约44%，其次是24岁以下用户约23%，40岁以上用户约33%；在地域分布上，二线及以上城市用户占比达到46%，新增用户也主要集中在一线、新一线和二线城市；在消费方面，知乎用户本科及以上学历比例超过70%，月收入8000元以上占比超过45%，家庭月均支出6377元，高于社区平台平均的5889元，展现出较强的消费力和品质导向@iresearch2024；

+ 小红书的核心用户群体以95后为主，约占50%，00 后亦占很大份额，约35%，85%的用户为年轻世代；特别地，小红书用户在性别上以女性为主，约占70%；地域分布集中在一二线城市，占比约 50%；平台规模庞大，月活跃用户约 3 亿，分享者超过 1 亿，月度内容搜索参与率达 70%@qiangua20250424；

总体来看，各大主流社交平台的用户群体均以年轻人为主，年龄集中在18至35岁之间，显示出“拼好饭”讨论主体很可能同样偏向年轻群体；在地域分布上，一线及新一线城市用户活跃度较高，但抖音、小红书等平台在低线城市也有庞大用户群，这为推测“拼好饭”在下沉市场的接受度提供了参考。消费特征方面，知乎与微博用户展现出较强的消费能力和品质追求，而小红书、B站用户则更注重兴趣与潮流导向，抖音用户的分层差异则提示我们需要分别考察年轻群体（数码、时尚、娱乐偏好）与中年群体（家庭、汽车、日用品偏好）在“拼好饭”中的态度。

*拼好饭平台用户画像。*为了更好地了解“拼好饭”平台的用户画像，这部分调查结果完整覆盖了消费者、商家、外卖骑手三种角色：

+ 消费者：主要为 20-34 岁年轻群体，集中在都市白领与学生；外卖整体渗透率：2023 年达到 49.6%，用户规模 5.35 亿，其中 35 岁以下是消费主力；2024 年 1 月“拼好饭”已覆盖 247 个城市，一线和新一线渗透率达 100%，部分城市单量占比高达 25%；主要消费动机为“拼好饭”极低的单价和较高的拼单补贴力度，拼好饭客单价普遍在 15 元左右，仅为普通外卖均价（约 47.4 元）的 1/3@htzq20240709；

+ 商家：入驻商家以中小商家为主，利用低价吸引订单，达到“以价换量”的目的，个别品牌（如古茗、茶百道）会上线低销或低成本单品以清库存或引流；高端茶饮（如喜茶、奈雪）入驻动力不足@htzq20240709；

+ 外卖骑手：拼好饭采用“畅跑模式”，集中出餐+集中目的地配送，平均拼单量 2-3 单，配送效率为普通外卖的 2-3 倍；主站中骑手收入约 7 元/单，“拼好饭”中仍按单计费，但平台补贴约 1.5 元/单，骑手每趟配送收入约 8.5 元，比主站提升 21%@htzq20240709；

综合来看，主流社交平台和“拼好饭”的用户画像高度契合：核心人群均为18—35岁的年轻群体，一线、新一线城市用户活跃，同时在低线城市释放潜力；消费特征上，知乎、微博用户更强调品质与消费力，而B站、小红书、抖音用户更注重性价比与兴趣潮流，与“拼好饭”15元左右的低价优势相符。整体上，消费者追求高性价比，商家以价换量获客，骑手依托集中配送提升效率，三方共同构成了“拼好饭”快速发展的用户生态基础。

*舆论核心议题。*经过词频统计分析，我们得到网络上用户讨论和关注的热点话题：

+ 低价优势与质量担忧：“拼好饭”作为外卖界的拼多多，以极致的低价吸引大量用户下单；同时也有担忧认为商家会以次充好@jmxw20241210；

+ 商家与平台的压力与博弈：“拼好饭”平台压低单价导致商家走货量提升但是整体利润提升不明显@txxw20241010；平台抽成规则与主站不同，商家面对固定到手价、额外增值服务费用、变高的平台佣金，许多人感叹“薄利多销”已经难以为继@jmxw20241210；

+ 用户行为与评价两极分化：“拼好饭”的数据表现强劲，日单峰值突破800万单，累计用户已达1.2亿，约占美团外卖总用户的四分之一@txxw20241010；“拼好饭”在网络上却备受嘲讽，例如“拼好饭吃多了”“玩得好像拼好饭吃中毒了”“吃两顿拼好饭就老实了”等，这些幽默调侃背后其实反映了用户对极低价外卖的复杂态度@jmxw20241210；

=== 网络问卷调查结果

- 受访者基础信息分布情况，包括年级分布、地域分布、月平均可支配收入分布和对“拼好饭”平台的使用情况分布：

#figure(
  grid(
    columns: 2,
    gutter: 10pt,
    image("asset/问卷年龄分布.png"), image("asset/问卷地域分布.png"), 
    text("（1）年级分布图", size: 10pt), text("（2）地域分布图", size: 10pt),
    image("asset/问卷收入分布.png"), image("asset/问卷使用情况.png"),
    text("（3）月均可支配收入图", size: 10pt), text("（4）拼好饭使用情况图", size: 10pt),
    ),
  caption: [受访者基础信息分布图],
)

从图中可以看出，受访者绝大部分是大三的学生，主要来自新一线城市，每个月能够支配的收入大部分不超过2000元，并且大部分都听说并使用过“拼好饭”平台。由此可见，在大学生这个“低收入”群体中拼好饭的渗透率非常高，其中绝大部分都有听说或使用“拼好饭”平台。

#pagebreak()
- 使用原因与评价：

#figure(
  image("asset/问卷使用原因.png", width: 65%),
  caption: [拼好饭使用原因]
)

#figure(
  image("asset/问卷评价条形图.png", width: 65%),
  caption: [拼好饭评价情况]
)<pingjiatiaoxingtu>

从中可以看出，“拼好饭”绝对的优势就是“廉价”，所有受访者全部都表示自己使用“拼好饭”的原因之一是“价格低”；另外有接近九成的受访者表示因为“补贴力度”大才使用“拼好饭”，这更加说明了“拼好饭”极致的低价策略对于大学生群体的吸引力；从受访者对于拼好饭的评价情况中也可以看出，“性价比高”这一评价的认可度非常高。

另外，从@pingjiatiaoxingtu 中可以看出大部分受访者对于食品安全持中立态度，但完全同意“拼好饭”食品安全有保障的只有极少数；对于是否愿意长期使用“拼好饭”受访者呈现两极分化趋势，可见“拼好饭”平台在大学生群体中复杂的地位，据此推测一部分人是认可并接受“拼好饭”的模式，也有相当一部分人可能只是在月末等“手头紧”的情况下才会使用“拼好饭”来凑合。

#pagebreak()
- 对“拼好饭”的影响认知情况，重点调查受访者关于“拼好饭”对商家和骑手的影响进行调查：

#figure(
  image("asset/问卷骑手影响.png", width: 65%),
  caption: [对拼好饭的影响的认知]
)

从中可以看出，大部分受访者都不认为“拼好饭”提高了配送效率和增加了骑手的收入；对于商家，大部分受访者认为商家的利润空间确实被压缩了，但是商家可以通过“拼好饭”平台获得流量曝光。

=== 实地走访调查结果

*消费者端。*实际调查情况显示，受访者对于“拼好饭”基本持中立态度，没有明显的排斥和喜好，当问及“食品安全”相关的问题时，受访者表示：“一开始还是有点担心，但吃了一次感觉还行，虽然确实不如堂食看上去那么精致、分量那么足，但质量应该没问题”，这与问卷调查结果一致，说明大部分消费者对于“食品安全”的判断是基于“吃了没事儿”得到的。当然，所有受访者都表示使用“拼好饭”平台的主要原因就是“低价”，这与网络问卷调查结果契合。当提及“拼好饭网络热梗”的相关话题时，大部分受访者表示网络上的梗听听就行，但“月末没钱了该拼还是得拼”，说明大学生消费者群体总的来说还是比较“实在”的，对于网络上的言论比较理性，没有盲目跟风。

*商家端。*受访的商家是一位经营小餐馆的餐饮从业者，主营业务为家常炒菜，其店铺已入驻“拼好饭”平台。根据其介绍，“拼好饭”模式在初期的确带来了一波订单量的提升，尤其是午餐高峰期的标准化套餐销量增加明显，几乎是入驻前的2到3倍。但他也坦言，“拼好饭”带来的利润并不高，平台的抽成规则让每一单的利润基本只有“一块多点儿”，虽然销量很好看但赚的钱并没有那么多，反而还比原来累得多。对于消费者关心的“食品安全”问题，受访者表示：“我们出餐标准和普通外卖一样，毕竟真忙起来根本就分不清是哪个渠道的订单”；当被问及网络上一些对“拼好饭”食品质量存在问题的吐槽时，他回应说：“饭多菜少的情况可能确实是存在，毕竟只有那么一点利润嘛，但质量我反正是不敢造假的，钱没赚多少把自己饭碗砸了。”整体来看，商家对于“拼好饭”态度较为务实，既看到其带来的流量红利，也对持续低价可能带来的经营压力有所担忧，这位受访者也表示想继续使用“拼好饭”平台一段时间，等销量数据起来之后就退出，毕竟这工作压力确实挺大。

*外卖骑手端。*受访骑手表示，他对“拼好饭”订单的整体印象是“单价低、频次高、集中送”。他说：“一般一个学校点里，会有好几个‘拼好饭’订单集中送过去，派单也比较集中，送餐 跟批发一样”，但相应地，“这种单子价钱也低一些，有时候一趟下来跑五六单才赚十几块”。当问到是否觉得“拼好饭”订单增加了配送负担时，他表示：“其实还好，平台给的时间充足，只要不是大中午暴热天，问题不大。”值得注意的是，该骑手也提到，“拼好饭”订单大多数集中在学生群体中，节省了他们分批送达的时间，送餐效率相对较高。总体来看，骑手对“拼好饭”订单持中性偏积极态度，认为虽然利润偏低，但操作效率高，配送体验尚可接受。

== 拼好饭商业模式分析

=== 传统外卖模式分析

传统外卖平台本质上是O2O（Online to Offline）商业模式的典型代表，即通过线上平台整合线下商户资源，为用户提供从线上下单到线下服务的完整闭环体验。这种模式的核心在于利用互联网技术打破信息壁垒，提高交易效率。在O2O框架下，外卖平台的商业核心是“三边市场”模型，美团，饿了么等平台同时服务于三类不同的群体：消费者、商家和骑手。而平台作为中间方，通过连接这三方来实现价值创造和盈利转化@zhang2021analysis@dai2023group。

从运营机制来看，这一模式形成了完美的闭环。商家通过平台提供的管理系统上传菜品信息，展示餐厅详情；消费者通过用户端浏览菜单并下单；平台接收订单后自动调配骑手完成配送任务。整个过程中，平台不仅为商家提供了订单管理、营销推广等全套服务，还通过实时定位、订单追踪等功能为消费者提供了便捷的消费体验，同时为骑手提供了订单分配和路径优化等技术支持。由此可见，外卖平台实质上构建了一个标准化的服务生态系统，通过技术手段实现了点餐、配送、管理等各环节的数字化协同，形成了高效的多边市场运营模式。

在这一运营模式的基础上，传统外卖平台通过多元化的收入来源构建其商业盈利结构。佣金收入作为最重要的盈利来源，平台按订单金额的一定比例向餐厅收取费用@eleme_meituan_waimai_20240202。配送服务收入在平台营收中也占据重着要的地位，以美团为例，2024年其核心本地商业业务中配送服务收入达980.65亿元，占比高达39%。然而，配送服务虽然收入规模庞大，但同时也是平台最大的成本支出项，2024年上半年美团配送服务单均亏损0.34元，全年配送成本占核心本地商业营收的39%@takeaway_profit_20250429。

但随着近年来外卖市场趋于饱和，传统的收取佣金的盈利模式在激烈的平台价格竞争环节面临着巨大的挑战。因此，在线营销服务成为外卖平台新一个盈利增长点@eleme_meituan_waimai_20240202。平台通过为商家提供推广服务，帮助餐厅获取更多曝光和流量，并收取相应的广告费用。美团2024年在线营销服务收入达488.36亿元，占核心本地商业业务收入的20%，广告收入占比达14.5%，与佣金合计贡献了约70%的利润，与此同时，饿了么同样推出了品牌推广、活动营销等多种广告产品，显示出营销服务的高盈利特性。

*然而，传统外卖平台的商业模式在发展中暴露出一系列结构性问题。*从盈利模式来看，O2O的致命弱点在于其盈利逻辑的不合理性。可持续性盈利模式的扩张实质上是一种野蛮的增长，将一个本质上亏损的业务放大千倍万倍，并不能改变其商业逻辑的缺陷@eleme_meituan_waimai_20240202。

以饿了么的发展历程为例，可以清晰地看到传统外卖平台盈利模式的演变轨迹。早期阶段，平台抽取交易额13%的佣金，但这一模式很快在同类产品的价格竞争中被放弃。第二阶段转向收取管理费加竞价排名的模式，当商家通过平台每月订单达到一定数值后，平台向商户收取固定管理费，同时推出竞价排名服务——排名前三位收费9600元/季度，其他位置约10000元/年，准入门槛为5800元/年。第三阶段则是大规模烧钱扩张，通过用户规模的增长来支撑广告和竞价排名等服务的收入增长@eleme_meituan_waimai_20240202。

这种模式演变反映了传统外卖平台面临的多重困境。对商家而言，平台的强制性收费模式不断压缩其利润空间，类似于淘宝与店家关系的演变——成长阶段平台为商家带来流量红利，但随着市场成熟，平台开始收取各种广告流量费，小商家的生存空间被不断挤压。对平台自身而言，尽管对商家施加压力，但依旧难以实现可持续盈利，O2O固有的特点导致线下运营团队过于庞大，微薄的利润不足以支撑整个体系的运营支出。

此外，更为关键的是用户端的矛盾。被互联网补贴宠坏的用户不愿意为平台服务付费，深层原因在于缺乏差异化的VIP服务，而普通用户更不愿意承担额外费用。作为缺乏用户粘性的订餐平台，一旦开始收费，用户会迅速转向其他平台，而行业缺乏技术门槛的特点使得新的挑战者不断涌现。

正是在传统外卖模式面临盈利困境、成本高企、用户价格敏感度提升的背景下，"拼好饭"作为一种全新的商业模式应运而生。

=== 拼好饭模式分析

拼好饭采用的是“外卖团购”模式，其商业逻辑的核心在于将零散的个人订单聚合为大规模的团购订单，通过规模效应来实现成本降低和效率提升@zhang2025influence。这种模式从根本上改变了外卖行业的运作方式。它不再单纯依靠单笔订单的佣金收入，而是通过订单聚合创造全新的价值链。通过“拼单”功能，平台能够将同一时段、同一区域的多个用户需求整合成批量订单。这种预售模式为商家提供了更好的生产计划性，使其能够一次性制作大量相同的餐品，从而大幅降低单位制作成本，不仅提高了商家的运营效率，也为平台提供了成本优化空间。

这种成本结构的优化，直接支撑了拼好饭的低佣金策略@zhang2025influence。低佣金策略一方面能够吸引对价格敏感的消费者，另一方面也为商家提供了更大的利润空间，形成了平台、商家、消费者的三方共赢局面。通过极致的价格优势，成功切入了对价格极为敏感的市场细分，为众多普通消费者提供了经济实惠的用餐选择。

值得注意的是，拼好饭的盈利重点并非短期内每笔订单的直接利润，而是着眼于长期的可持续增长和用户获取@zhang2025influence。尽管拼好饭的平均订单价值相对较低，但它发挥着重要的流量入口作用，能够有效吸引对价格敏感的用户群体，并将其转化为平台的活跃用户。这种战略性定位使得拼好饭在美团整体生态中承担着用户拓展和市场巩固的重要功能。通过提供极具竞争力的价格，不仅能够增强现有用户的粘性，还能够吸引新用户进入美团生态系统。一旦这些用户习惯了平台的服务，就有可能被引导至其他高利润业务，如常规外卖、到店消费、旅游出行等，从而实现整体收益的最大化。

这一增长策略的有效实施，高度依赖于其规模效应的持续放大。 拼好饭模式的成功很大程度上依赖于规模效应的发挥。随着参与拼单的用户数量增加，单个订单的平均成本会持续下降，价格优势会更加明显，进而吸引更多用户参与，形成正向的网络效应循环。这种规模驱动的商业逻辑使得拼好饭具备了快速扩张和市场渗透的潜力。同时，大量的订单聚合也为平台提供了丰富的数据资源，通过对用户消费习惯、区域需求特征等数据的深度挖掘，平台可以进一步优化供应链管理、提升服务精准度，创造更大的商业价值。

综上所述， 拼好饭构建了一种“低佣金、低成本、高效率、薄利多销”的创新商业模式，通过订单聚合和规模效应的充分利用，在传统外卖市场的高成本结构中找到了突破口，为外卖行业的发展提供了全新的思路。

== 拼好饭背后的社会经济分析

=== 对比研究结果

我们对收集到的数据进行了对比分析，结果显示网络上的舆论和现实中的消费行为之间存在明显差异。

在舆论层面，社交平台的用户群体以年轻人为主，但由于消费能力和价值取向不同，对拼好饭的评价出现了分化。微博、知乎上的用户消费水平较高，更强调品质和生活体验，因此往往将拼好饭看作“低质”“凑合”的代表。而在小红书与B站，用户则更习惯以潮流和娱乐的方式参与讨论，他们会通过“玩梗”来放大拼好饭的低价特征，使其在舆论空间中带有一定的调侃意味。总体来看，网络讨论更多表现为情绪化和群体文化态度的表达，而不一定反映真实的消费选择。

与此相对，现实调查呈现出的情况截然不同。数据显示，拼好饭在年轻群体，特别是大学生和初入职场的群体中渗透率极高。对于月均收入不足2000元的学生来说，“低价+补贴”是最直接的吸引力，拼好饭15元左右的客单价明显低于普通外卖，能够满足他们的日常需求。大多数消费者认可拼好饭的性价比优势，但在食品安全和长期使用的态度上存在分歧：部分人愿意长期依赖，另一部分则只在经济紧张时选择。对于平台带来的影响，受访者普遍认为商家的利润空间被压缩，但获得了额外的流量和曝光；而骑手的配送效率有所提高，但收入提升并不显著。换言之，现实中的消费行为更多体现出在有限预算下的理性选择。

通过这种对比可以看出，网络舆论与现实消费之间的反差，实际上反映了当下社会的消费心态：一方面，消费者希望获得更好的品质保障；另一方面，在收入增速放缓、支出压力加大的环境下，他们不得不优先考虑价格优惠和实际利益。拼好饭的兴起，不仅说明年轻群体的消费水平和消费意愿正在发生变化，也揭示了当前时代经济生活的几个特征：支出更谨慎，对价格更敏感，平台经济通过拼单和集中配送来重新组织供需关系。舆论与现实的差距，从更深层次来看，是社会消费心理与经济条件之间的张力，而拼好饭正是这一转型时期的典型表现。


=== 统计数据结果与分析

我们系统汇集了国家统计局、行业研究机构以及主要外卖平台发布的关键指标，以全面分析拼好饭所折射出的社会经济趋势。

首先，从宏观层面看，外卖行业在当前经济环境下仍保持高速增长。2015年至2023年，我国餐饮市场规模由3.23万亿元扩大至5.29万亿元，复合年增长率达6.4%；同期外卖市场规模则由0.13万亿元跃升至1.5万亿元，复合年增长率高达36.45%，在餐饮总额中的占比由3.9%提升至28.3%。与此同时，外卖用户规模由3.64亿人增加到5.35亿人，渗透率接近一半。受性价比消费趋势影响，2023年人均餐饮消费降至42.6元，美团外卖客单价则维持在47.4至52元之间，反映出消费者在支出趋紧的环境下更加关注价格优势。未来行业增长将更多依赖消费场景拓展与商品多样化所带来的订单频次提升。@meituan_pinhuaifan_20240908

其次，在外卖行业整体扩张的背景下，拼好饭模式快速渗透。据交通国际数据，2023年拼好饭订单量超过11.6亿单，占美团外卖订单总量约6%；预计2024年一季度，日均订单量将同比增长约67%，由300万单增至500万单，全年占比有望提升至8%–9%。@pinhuaifan_attack_20240906 自2022年4月在武汉等地试点以来，拼好饭日订单量突破100万；2023年进入北上广深等一线城市后进一步扩张，到2024年二季度单日峰值已超过800万单。目前已有蜜雪冰城、华莱士、正新鸡排、塔斯汀等大众品牌，以及汉堡王、老乡鸡、魏家凉皮、古茗、茶百道、沪上阿姨、绝味鸭脖、永和大王等5000余家餐饮品牌入驻，推动订单规模持续攀升。@pinghaofan_c2m_20250717

再次，从价格与消费结构看，拼好饭通过集中拼单实现低价优势，平均客单价约15元，比主站普遍低15%以上，并配合首单优惠，折扣幅度可达50%。与常规外卖相比，拼好饭订单价格通常低50%–70%，且免除配送和包装费用，因而对价格敏感的青年群体具有强大吸引力。这一模式既满足了“精打细算”的消费需求，也促进了中低价位餐饮品类的增长。@pinghaofan_c2m_20250717

最后，从劳动市场角度看，拼好饭通过“畅跑模式”实现集中取餐与配送，提升骑手单位时间的完成单量，降低人均配送成本，从而增强平台整体效益。对用户而言，它提供了低价高效的用餐选择；对商家而言，突破了以品牌排序为主的流量逻辑，改为按品类推荐产品，既帮助中小商家获得曝光，也为知名品牌清库存、推新品提供渠道；对骑手而言，则通过订单集约化提升劳动效率，形成用户、商家和骑手三方共赢的良性循环。@pinghaofan_c2m_20250717

这些数据揭示了几个关键现象：一是外卖行业的持续扩张表明人们的消费习惯正在被重塑，外卖已从“偶尔便利”演变为日常刚需；二是人均消费下降和客单价稳定说明消费者在经济压力下更强调性价比，这也是拼好饭能够迅速扩张的根本原因；三是拼好饭模式的普及不仅推动了外卖市场下沉和商家结构优化，也通过配送效率提升带动了劳动市场的良性调整。这些变化共同反映出当前时代经济运行的突出特征——成本控制与效率提升成为市场竞争的核心逻辑。

////////////////// 研究与讨论 //////////////////

= 研究与讨论

本节承接上一节“调查结果与数据分析”，在已有数据与访谈事实基础上，从“舆论—行为差异”“消费结构变化”“宏观经济特征”三方面展开深入探讨，力求从更深层次解释拼好饭现象背后的逻辑与启示。

== 网络舆论与现实消费的差异
调查结果显示，网络上的讨论与现实中的选择之间存在显著差异。网络空间往往放大了情绪化表达与群体文化特征。微博、知乎等平台用户消费力较强，更倾向于将拼好饭视作“低质”“凑合”的象征，其讨论带有明显的价值判断。而在小红书、B站等平台，拼好饭则更多被娱乐化、符号化处理，成为调侃和玩梗的对象。换句话说，舆论话题并不完全指向实际消费体验，而是折射出群体文化和身份认同。

然而，现实中的选择却表现出务实的一面。问卷与实地走访结果表明，在大学生和初入职场的年轻群体中，拼好饭的渗透率极高。价格低廉和补贴力度成为最核心的吸引力，远比口碑和品牌更有决定性。这说明网络言论与实际消费之间存在“温差”，前者更多是一种文化表达，而后者则基于预算与需求的现实考量。理解这一差异，有助于避免以“声音最大”的群体代表整体趋势的片面误判。

== 消费水平与消费意愿的转变
从消费结构的变化来看，当下年轻群体表现出明显的价格敏感与理性消费倾向。在收入增速放缓、生活成本上升的环境中，他们在就餐选择上不再一味追求品质溢价，而是更强调“够用”和“划算”。拼好饭正是在这一背景下获得了快速发展，其平均客单价约为普通外卖的三分之一，满足了低收入群体的日常需求。

值得注意的是，这种消费理性不仅体现在价格选择上，也体现在消费方式上。越来越多的年轻人愿意通过拼单、团购等方式来降低人均支出，展现出集体化和共享化的消费趋势。这种“抱团取暖”式的选择不仅节省了开支，也带有一定的社交意味，反映出消费文化正在从个体化转向更具合作性的模式。

== 当前时代的经济特征
拼好饭的兴起不仅是一个商业案例，也折射出更宏观的经济特征。首先，谨慎消费已成为常态。无论是年轻学生还是都市白领，在经济环境趋紧的背景下，更多人选择用降低单次支出来维持消费频率，形成了“降价—增频—控总额”的模式。这种行为逻辑表明居民的消费信心仍未完全恢复，而价格因素已成为首要考量。

其次，效率驱动逐渐取代补贴驱动。传统外卖平台依赖补贴吸引用户，但难以持续；拼好饭通过集中备餐和“畅跑模式”配送，将多笔零散订单合并，大幅度降低了单位成本，提高了商家与骑手的效率。与其说它是价格战的产物，不如说它是效率提升的结果。

最后，平台生态正在实现再平衡。拼好饭不仅作为低价入口吸引用户，更在美团整体生态中承担着导流和沉淀用户的功能。通过让消费者先在低价板块建立习惯和粘性，再逐步引导他们进入利润更高的业务板块，平台实现了从用户规模到生态收益的转化。这种生态战略说明，拼好饭不仅是一种短期市场策略，更是平台在竞争格局下寻求长期平衡的关键环节。

总体而言，拼好饭现象让我们看到，网络舆论与现实消费之间的差异，消费心态的理性化与共享化趋势，以及在宏观经济压力下，平台如何通过效率和生态优化寻找新的增长空间。这些特征不仅有助于理解当下的餐饮行业，也为未来平台经济的发展提供了参考。

////////////////// 总结与展望 //////////////////

= 总结与展望

通过对拼好饭的舆情分析、问卷调查与实地走访，本次研究揭示了网络话语与现实消费之间的差距。网络上，拼好饭常被简化为“低质”“凑合”的符号，而现实中，尤其是在大学生和年轻上班族群体中，它却以极高的使用率展现出强劲的生命力。这种差异说明，在社会实践调查中，不能单纯依赖舆论声量来判断现象的真实面貌，而需要多源数据交叉验证，以减少偏差，得到更贴近实际的结论。

从消费行为来看，年轻群体在经济压力下表现出明显的价格敏感与理性选择。他们在日常就餐中更强调性价比与确定性，而不是品牌溢价或服务多样化。拼好饭以低价和集中化配送满足了这种需求，形成了以“够用”为导向的消费习惯。对于商家而言，这一模式并非单纯的“以价换量”，而是依靠批量化生产和标准化流程来控制成本，提升效率，在低利润空间中寻找新的平衡点。平台则通过拼好饭这一入口业务扩展用户群体，并在生态层面实现导流和价值延伸。

这一现象同时也提出了新的治理和社会议题。低价模式背后伴随着食品安全、商家盈利压力以及骑手劳动强度等问题，如何在保障消费者需求的同时维护产业健康发展，是平台与监管者都需要面对的挑战。从更长远的角度看，拼好饭的出现不仅是餐饮行业的一次商业创新，也映射出当下社会的经济特征：谨慎消费成为常态，效率驱动取代了补贴驱动，平台经济不断寻求新的平衡与优化。

总体而言，拼好饭为我们提供了一个观察社会消费心理与经济运行逻辑的窗口。它揭示了居民在后疫情时代的消费结构调整与心态转变，也为未来的产业实践和政策制定提供了启示。通过这一案例，我们能够更加深刻地理解消费行为背后的社会经济动因，从而在实践中积累经验，为构建更加可持续与公平的市场环境贡献思路。


////////////////////// 引用文献 //////////////////////
#pagebreak()
#apply-ref-style[

#bibliography(
  "ref.bib",
  title: config.reference_title,
  style: "gb-7714-2015-numeric"
)

]
#pagebreak()

/////////////////////// 附录 ///////////////////////
#apply-appendix-style[

= 附录

#set heading(outlined: false) //隐藏附录子标题
== 爬虫代码

```python
import time
import json
import csv
import re
from datetime import datetime, timedelta
from seleniumbase import BaseCase
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd


class SocialMediaScraper(BaseCase):
    def setUp(self):
        super().setUp()
        self.results = []
        self.keyword = "拼好饭"
        self.start_date = datetime(2024, 7, 1)  # 2024年下半年开始
        self.end_date = datetime(2025, 6, 30)   # 2025年上半年结束

    def safe_get_text(self, element):
        """安全获取元素文本"""
        try:
            return element.text.strip() if element else ""
        except:
            return ""

    def parse_date(self, date_str):
        """解析各种日期格式"""
        try:
            # 处理常见的中文日期格式
            if "小时前" in date_str:
                hours = int(re.search(r'(\d+)', date_str).group(1))
                return datetime.now() - timedelta(hours=hours)
            elif "天前" in date_str:
                days = int(re.search(r'(\d+)', date_str).group(1))
                return datetime.now() - timedelta(days=days)
            elif "月前" in date_str:
                months = int(re.search(r'(\d+)', date_str).group(1))
                return datetime.now() - timedelta(days=months*30)
            # 添加更多日期格式解析...
            return datetime.now()
        except:
            return datetime.now()

    def is_date_in_range(self, post_date):
        """检查日期是否在目标范围内"""
        return self.start_date <= post_date <= self.end_date

    def scrape_weibo(self):
        """爬取微博数据"""
        print("开始爬取微博数据...")
        try:
            # 微博搜索页面
            search_url = f"https://s.weibo.com/weibo?q={self.keyword}"
            self.open(search_url)
            self.wait_for_element("div.card-wrap", timeout=10)

            # 滚动加载更多内容
            for i in range(3):
                self.scroll_to_bottom()
                time.sleep(2)

            # 获取帖子列表
            posts = self.find_elements("div.card-wrap")

            for post in posts[:20]:  # 限制数量避免过度请求
                try:
                    # 提取帖子信息
                    content = self.safe_get_text(post.find_element(By.CSS_SELECTOR, "p.txt"))
                    author = self.safe_get_text(post.find_element(By.CSS_SELECTOR, "a.name"))
                    date_elem = post.find_element(By.CSS_SELECTOR, "a.from")
                    date_str = self.safe_get_text(date_elem)
                    post_date = self.parse_date(date_str)

                    # 检查日期范围
                    if self.is_date_in_range(post_date):
                        # 获取互动数据
                        try:
                            likes = self.safe_get_text(post.find_element(By.CSS_SELECTOR, "span.woo-like-count"))
                            comments = self.safe_get_text(post.find_element(By.CSS_SELECTOR, "span.woo-comment-count"))
                            shares = self.safe_get_text(post.find_element(By.CSS_SELECTOR, "span.woo-forward-count"))
                        except:
                            likes = comments = shares = "0"

                        self.results.append({
                            'platform': '微博',
                            'author': author,
                            'content': content,
                            'date': post_date.strftime('%Y-%m-%d'),
                            'likes': likes,
                            'comments': comments,
                            'shares': shares,
                            'url': self.get_current_url()
                        })

                except Exception as e:
                    print(f"处理微博帖子时出错: {e}")
                    continue

        except Exception as e:
            print(f"微博爬取出错: {e}")

    def scrape_xiaohongshu(self):
        """爬取小红书数据"""
        print("开始爬取小红书数据...")
        try:
            # 小红书搜索页面
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={self.keyword}"
            self.open(search_url)
            self.wait_for_element("div.note-item", timeout=10)

            # 滚动加载
            for i in range(3):
                self.scroll_to_bottom()
                time.sleep(3)

            # 获取笔记列表
            notes = self.find_elements("div.note-item")

            for note in notes[:15]:  # 限制数量
                try:
                    # 点击笔记进入详情页
                    note.click()
                    time.sleep(2)

                    # 提取信息
                    title = self.safe_get_text(self.find_element("h1.title"))
                    content = self.safe_get_text(self.find_element("div.content"))
                    author = self.safe_get_text(self.find_element("div.author-info .name"))

                    # 获取互动数据
                    try:
                        likes = self.safe_get_text(self.find_element("span.like-count"))
                        comments = self.safe_get_text(self.find_element("span.comment-count"))
                    except:
                        likes = comments = "0"

                    self.results.append({
                        'platform': '小红书',
                        'author': author,
                        'title': title,
                        'content': content,
                        'date': datetime.now().strftime('%Y-%m-%d'),  # 小红书日期较难获取
                        'likes': likes,
                        'comments': comments,
                        'shares': '0',
                        'url': self.get_current_url()
                    })

                    # 返回搜索页面
                    self.go_back()
                    time.sleep(1)

                except Exception as e:
                    print(f"处理小红书笔记时出错: {e}")
                    self.go_back()
                    continue

        except Exception as e:
            print(f"小红书爬取出错: {e}")

    def scrape_zhihu(self):
        """爬取知乎数据"""
        print("开始爬取知乎数据...")
        try:
            # 知乎搜索页面
            search_url = f"https://www.zhihu.com/search?type=content&q={self.keyword}"
            self.open(search_url)
            self.wait_for_element("div.SearchResult-Card", timeout=10)

            # 滚动加载
            for i in range(3):
                self.scroll_to_bottom()
                time.sleep(2)

            # 获取搜索结果
            cards = self.find_elements("div.SearchResult-Card")

            for card in cards[:20]:
                try:
                    # 提取信息
                    title_elem = card.find_element(By.CSS_SELECTOR, "h2.ContentItem-title a")
                    title = self.safe_get_text(title_elem)

                    # 获取内容摘要
                    try:
                        content = self.safe_get_text(card.find_element(By.CSS_SELECTOR, "span.RichText"))
                    except:
                        content = ""

                    # 获取作者
                    try:
                        author = self.safe_get_text(card.find_element(By.CSS_SELECTOR, "a.UserLink-link"))
                    except:
                        author = "匿名用户"

                    # 获取互动数据
                    try:
                        vote_elem = card.find_element(By.CSS_SELECTOR, "button.VoteButton")
                        votes = self.safe_get_text(vote_elem)
                    except:
                        votes = "0"

                    self.results.append({
                        'platform': '知乎',
                        'author': author,
                        'title': title,
                        'content': content,
                        'date': datetime.now().strftime('%Y-%m-%d'),
                        'likes': votes,
                        'comments': '0',
                        'shares': '0',
                        'url': title_elem.get_attribute('href') if title_elem else ""
                    })

                except Exception as e:
                    print(f"处理知乎内容时出错: {e}")
                    continue

        except Exception as e:
            print(f"知乎爬取出错: {e}")

    def scrape_douyin_web(self):
        """爬取抖音网页版数据"""
        print("开始爬取抖音网页版数据...")
        try:
            # 抖音网页版搜索
            search_url = f"https://www.douyin.com/search/{self.keyword}"
            self.open(search_url)
            self.wait_for_element("div.video-info", timeout=10)

            # 滚动加载
            for i in range(3):
                self.scroll_to_bottom()
                time.sleep(3)

            # 获取视频列表
            videos = self.find_elements("div.video-info")

            for video in videos[:15]:
                try:
                    # 提取视频信息
                    title = self.safe_get_text(video.find_element(By.CSS_SELECTOR, "p.title"))
                    author = self.safe_get_text(video.find_element(By.CSS_SELECTOR, "span.name"))

                    # 获取互动数据
                    try:
                        likes = self.safe_get_text(video.find_element(By.CSS_SELECTOR, "span.like-count"))
                        comments = self.safe_get_text(video.find_element(By.CSS_SELECTOR, "span.comment-count"))
                    except:
                        likes = comments = "0"

                    self.results.append({
                        'platform': '抖音',
                        'author': author,
                        'title': title,
                        'content': title,  # 视频标题作为内容
                        'date': datetime.now().strftime('%Y-%m-%d'),
                        'likes': likes,
                        'comments': comments,
                        'shares': '0',
                        'url': self.get_current_url()
                    })

                except Exception as e:
                    print(f"处理抖音视频时出错: {e}")
                    continue

        except Exception as e:
            print(f"抖音爬取出错: {e}")

    def save_results(self):
        """保存爬取结果"""
        if not self.results:
            print("没有爬取到数据")
            return

        # 保存为CSV
        df = pd.DataFrame(self.results)
        csv_filename = f"拼好饭_社交媒体数据_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"数据已保存到: {csv_filename}")

        # 保存为JSON
        json_filename = f"拼好饭_社交媒体数据_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        print(f"数据已保存到: {json_filename}")

        # 打印统计信息
        platform_counts = df['platform'].value_counts()
        print("\n爬取统计:")
        for platform, count in platform_counts.items():
            print(f"{platform}: {count}条")
        print(f"总计: {len(self.results)}条")

    def test_scrape_social_media(self):
        """主要的爬取测试方法"""
        print("开始爬取社交媒体平台数据...")
        print(f"关键词: {self.keyword}")
        print(f"时间范围: {self.start_date.strftime('%Y-%m-%d')} 到 {self.end_date.strftime('%Y-%m-%d')}")

        # 设置浏览器选项
        self.maximize_window()

        try:
            # 爬取各个平台
            self.scrape_weibo()
            time.sleep(5)  # 平台间延迟

            self.scrape_zhihu()
            time.sleep(5)

            self.scrape_xiaohongshu()
            time.sleep(5)

            self.scrape_douyin_web()

        except Exception as e:
            print(f"爬取过程中出错: {e}")

        finally:
            # 保存结果
            self.save_results()


class AdvancedSocialMediaScraper(SocialMediaScraper):
    """增强版爬虫，包含更多功能"""

    def __init__(self):
        super().__init__()
        self.comment_depth = 10  # 每个帖子最多爬取10条评论

    def scrape_comments(self, post_url, platform):
        """爬取评论数据"""
        comments = []
        try:
            self.open(post_url)
            time.sleep(2)

            if platform == "微博":
                comment_elements = self.find_elements("div.comment_txt")
            elif platform == "知乎":
                comment_elements = self.find_elements("div.ContentItem-content")
            elif platform == "小红书":
                comment_elements = self.find_elements("div.comment-item")
            else:
                return comments

            for i, comment_elem in enumerate(comment_elements[:self.comment_depth]):
                try:
                    comment_text = self.safe_get_text(comment_elem)
                    comment_author = self.safe_get_text(
                        comment_elem.find_element(By.CSS_SELECTOR, "a.name, .username, .author")
                    )

                    comments.append({
                        'comment_text': comment_text,
                        'comment_author': comment_author,
                        'platform': platform
                    })
                except:
                    continue

        except Exception as e:
            print(f"爬取{platform}评论时出错: {e}")

        return comments

    def filter_high_engagement(self, min_likes=100, min_comments=20):
        """筛选高互动帖子"""
        filtered_results = []

        for result in self.results:
            try:
                likes = int(re.sub(r'[^\d]', '', result.get('likes', '0')) or '0')
                comments = int(re.sub(r'[^\d]', '', result.get('comments', '0')) or '0')

                if likes >= min_likes or comments >= min_comments:
                    filtered_results.append(result)

            except:
                # 如果无法解析数字，保留该结果
                filtered_results.append(result)

        self.results = filtered_results
        print(f"筛选后剩余 {len(self.results)} 条高热度帖子")


def run_scraper():
    """运行爬虫的主函数"""
    scraper = AdvancedSocialMediaScraper()

    # 配置SeleniumBase
    scraper.setUp()

    try:
        # 执行爬取
        scraper.test_scrape_social_media()

        # 筛选高热度内容
        scraper.filter_high_engagement(min_likes=50, min_comments=10)

        # 最终保存
        scraper.save_results()

    except Exception as e:
        print(f"爬虫运行出错: {e}")

    finally:
        scraper.tearDown()


if __name__ == "__main__":
    # 使用说明
    print("""
    使用前注意事项:
    1. 安装依赖: pip install seleniumbase pandas
    2. 确保遵守各平台的服务条款和robots.txt
    3. 建议在非高峰时段运行，避免对服务器造成压力
    4. 某些平台可能需要登录或有反爬措施
    5. 请合理设置爬取频率和数量
    """)

    # 询问用户确认
    confirm = input("是否确认开始爬取? (y/n): ")
    if confirm.lower() == 'y':
        run_scraper()
    else:
        print("已取消爬取任务")


# 配置文件示例
CONFIG = {
    "platforms": {
        "weibo": {
            "enabled": True,
            "max_posts": 20,
            "delay": 2
        },
        "xiaohongshu": {
            "enabled": True,
            "max_posts": 15,
            "delay": 3
        },
        "zhihu": {
            "enabled": True,
            "max_posts": 20,
            "delay": 2
        },
        "douyin": {
            "enabled": True,
            "max_posts": 15,
            "delay": 3
        }
    },
    "filters": {
        "min_likes": 50,
        "min_comments": 10,
        "date_range": {
            "start": "2024-07-01",
            "end": "2025-06-30"
        }
    },
    "output": {
        "csv": True,
        "json": True,
        "excel": False
    }
}
```
#pagebreak()

== 问卷调查

1. 您的年级是

   A. 大一
   B. 大二
   C. 大三
   D. 大四
   E. 研究生

2. 您的性别是

   A. 男
   B. 女
   C. 不便回答

3. 您所在的城市类别是

   A. 一线城市
   B. 新一线城市
   C. 二线城市
   D. 三线及以下

4. 您是否听说过“拼好饭”

   A. 听说过并使用过
   B. 听说过但未使用
   C. 没听说过

5. 您近30天点外卖的频率是

   A. 1–3次
   B. 4–7次
   C. 8–15次
   D. 16次及以上

6. 您使用拼好饭的频率是（单选题，若未使用则跳过）

   A. 偶尔（1–2次/月）
   B. 较多（1–2次/周）
   C. 频繁（3次/周以上）

7. 您选择拼好饭的主要原因是 （多选题，最多选3项）

   A. 价格低
   B. 补贴力度大
   C. 配送速度快
   D. 品牌/朋友推荐
   E. 份量适合
   F. 其他

8. 您最近一次拼好饭的客单价（含配送费）是

   A. ≤10元
   B. 11–15元
   C. 16–20元
   D. 21–25元
   E. 26元以上

9. 您对拼好饭的评价（矩阵题）

#h(142pt)非常不同意 #h(13pt) 不同意 #h(30pt) 一般 #h(35pt) 同意 #h(23pt) 非常同意

#h(7em)性价比高 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(4em)食品安全有保障 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(3em)配送时间令人满意 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(2em)愿意长期使用拼好饭 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big


10. 您是否担心拼好饭的食品安全问题

    A. 非常担心
    B. 有些担心
    C. 一般
    D. 不太担心
    E. 完全不担心

11. 网络上对拼好饭的调侃是否影响您的使用意愿

    A. 明显减少了我的使用
    B. 略有影响
    C. 基本无影响
    D. 反而更愿意尝试

12. 您觉得拼好饭的价格优势和食品安全担忧哪个更重要（排序题）

  A. 价格优势
  B. 食品安全
  C. 配送效率
  D. 口味体验

#pagebreak()
13. 您认为拼好饭给商家和骑手带来的影响是（矩阵题）

#h(140pt)完全不同意 #h(15pt) 不同意 #h(27pt) 一般 #h(38pt) 同意 #h(22pt) 非常同意
    
#h(3em)商家利润空间缩小 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(2em)商家能借此引流获客 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(3em)骑手配送效率提高 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big

#h(5em)骑手收入增加 #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big #h(45pt) #sym.circle.stroked.big


14. 您认为拼好饭是否体现了“消费降级”现象

    A. 非常同意
    B. 比较同意
    C. 一般
    D. 不太同意
    E. 完全不同意

15. 您未来三个月对拼好饭的使用意向

    A. 明显增加
    B. 略有增加
    C. 持平
    D. 略有减少
    E. 明显减少

16. 如果拼好饭能明确标注食材来源与卫生评级，您是否愿意多付一些钱？

    A. 不愿意
    B. 愿意+1元
    C. 愿意+2元
    D. 愿意+3元及以上

17. 您主要通过哪些渠道了解拼好饭？（多选题）

    A. 抖音
    B. 小红书
    C. 微博
    D. 知乎
    E. B站
    F. 同学/同事推荐
    G. 其他

18. 您的月生活费/收入水平是

    A. ≤1000元
    B. 1001–2000元
    C. 2001–3000元
    D. 3001–5000元
    E. 5000元以上

19. 开放题：您对拼好饭最大的期待或担忧是什么？

#pagebreak()

== 活动图片

#figure(
  image("asset/采访外卖骑手.png", width: 75%),
  caption: [实地采访外卖骑手]
)

#figure(
    grid(columns: 2, gutter: 10pt,
    image("asset/采访消费者1.jpg"), image("asset/采访消费者2.jpg")
    ),
    caption: [实地采访消费者]
)

]
